{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## importing all the libraries needed\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class classifier:\n",
    "    \n",
    "    def __init__(self, normalize=True, clf_type = \"logistic\", split_ratio=0.3):\n",
    "        \"\"\"\n",
    "        Initializes the class with the right classifier attribute depending on the type of classifier\n",
    "        \"\"\"\n",
    "        if clf_type == \"logistic\":\n",
    "            self.clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "        elif clf_type == \"naive\":\n",
    "            self.clf = naive_bayes.MultinomialNB()\n",
    "        self.normalize = normalize\n",
    "        if self.normalize:\n",
    "            self.vec = TfidfVectorizer(use_idf=True)\n",
    "        else:\n",
    "            self.vec = TfidfVectorizer(use_idf=True, lowercase = True, strip_accents=ascii, stop_words = set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "        \n",
    "    def _read(self, documents):\n",
    "        \"\"\"\n",
    "        Reads and combines all the documents in one big pandas data frame\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        X,Y = [], []\n",
    "        for document in documents:\n",
    "            d_ata = pd.read_csv(document, sep='\\t', names=['review','label'])\n",
    "            data.append(d_ata)\n",
    "        data = pd.concat(data)\n",
    "        self.data = data\n",
    "        Y = data.label\n",
    "        self.vec.fit(data.review)\n",
    "        X = self.preprocess(data)\n",
    "        \n",
    "        return train_test_split(X,Y)\n",
    "    \n",
    "    def preprocess(self, data_f):\n",
    "        \"\"\"\n",
    "        Preprocesses the text data by turning it into frequency tables\n",
    "        Does a few normalization steps (lowercasing, removing stopwords ...) if self.normalize = true\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.vec.transform(data_f.review)\n",
    "    \n",
    "    def train(self, documents):\n",
    "        \"\"\"\n",
    "        Calls the train function\n",
    "        Trains the classifier object\n",
    "        \"\"\"\n",
    "        X_train, X_test, Y_train, Y_test =  self._read(documents)       \n",
    "                \n",
    "        self.clf.fit(X_train,Y_train)\n",
    "        print (X_train.shape,Y_train.shape)\n",
    "        \n",
    "        acc = roc_auc_score(Y_test,self.clf.predict_proba(X_test)[:,1])\n",
    "        \n",
    "        print (\"Accuracy: \",acc)\n",
    "        \n",
    "    def predict(self, sentence):\n",
    "        \"\"\"\n",
    "        Predicts for a sentence\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(StringIO(sentence), names=['review'])\n",
    "        X = self.preprocess(data)\n",
    "        Y = self.clf.predict_proba(X)\n",
    "        \n",
    "        return np.argmax(Y)\n",
    "    \n",
    "    def test_file(self, file_name):\n",
    "        \"\"\"\n",
    "        Tests with a file and outputs a file of labels\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        with open(file_name) as f:\n",
    "            for line in f.readlines():\n",
    "                print(line,self.predict(line))\n",
    "                labels.append(self.predict(line))\n",
    "        \n",
    "        with open('test_results.txt', 'w') as f:\n",
    "            for label in labels:\n",
    "                f.write(str(label)+\"\\n\")\n",
    "                \n",
    "        print (\"Results from \",file_name,\" printed to: output.txt\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnormalized data, Logistic regression\n",
      "(2061, 5116) (2061,)\n",
      "Accuracy:  0.896744853591\n",
      "\n",
      "Normalized data, Logistic regression\n",
      "(2061, 5155) (2061,)\n",
      "Accuracy:  0.920064186378\n",
      "\n",
      "Unnormalized data, Naive Bayes\n",
      "(2061, 5116) (2061,)\n",
      "Accuracy:  0.868579700272\n",
      "\n",
      "Normalized data, Naive Bayes\n",
      "(2061, 5155) (2061,)\n",
      "Accuracy:  0.91101953602\n"
     ]
    }
   ],
   "source": [
    "print (\"Unnormalized data, Logistic regression\")\n",
    "my_clf_ul = classifier(normalize=False)\n",
    "my_clf_ul.train([\"../project1/sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Normalized data, Logistic regression\")\n",
    "my_clf_nl = classifier(normalize=True)\n",
    "my_clf_nl.train([\"../project1/sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Unnormalized data, Naive Bayes\")\n",
    "my_clf_un = classifier(normalize=False, clf_type='naive')\n",
    "my_clf_un.train([\"../project1/sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Normalized data, Naive Bayes\")\n",
    "my_clf_nn = classifier(normalize=True, clf_type='naive')\n",
    "my_clf_nn.train([\"../project1/sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"../project1/sentiment_labelled_sentences/yelp_labelled.txt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf_nl.predict(\"This product is really good as fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This GPS tracker works like a charm.\n",
      " 1\n",
      "When I opened the box the product was not in the cutouts snd the protective cover was not on the unit\n",
      " 0\n",
      "Everyone should have one who owns a computer\n",
      " 0\n",
      "Buy something else\n",
      " 0\n",
      "Pure junk do not buy ever the greatest load of junk I have ever purchased ever\n",
      " 0\n",
      "The DataVac was used and full of dust and dirt\n",
      " 1\n",
      "Not so great...bought to clean the bobbin case area of my Brother and Baby Lock Quilting and Embroidery machines\n",
      " 1\n",
      "It is a great size, I keep it in my desk drawer at work and beause I teach wood shop it's going to get a lot of use\n",
      " 0\n",
      "I just bought this Vacuum. It's just good for nothing\n",
      " 0\n",
      "This is just perfect for vacuuming out the lint from my sewing machine\n",
      " 1\n",
      "I use it mostly to vacuum threads on the sewing machine. It is just the right size for this task.\n",
      " 1\n",
      "I have found this mini vac. to be everything it is said to be\n",
      " 1\n",
      "I ordered the Pork Prime Rib Chop it was beautiful, scrumptious and totally tender.\n",
      " 1\n",
      "A bastion of fine dining in The City for 20 years, Nancy Oakes' Boulevard continues to amaze\n",
      " 0\n",
      "Took my brand new bmw in for service. When I picked it up there were scratches all over the car.\n",
      " 0\n",
      "I'll never buy another car from this location again.\n",
      " 0\n",
      "Service Department, once the crown jewel of this dealership, has definitely lost its shine.\n",
      " 1\n",
      "Kevin is very friendly, accommodating and has excellent customer service!\n",
      " 1\n",
      "Had a great experience leasing a new car here working with James Anwari.\n",
      " 1\n",
      "Following the showing we were all dissapointed by a mess of a movie with little plot and little thought which only served as a pit stop for infinity war.\n",
      " 0\n",
      "Shame I can't rate this 0/10\n",
      " 1\n",
      "This movie has it all, Great acting , action, effects , costumes, music and scenery.\n",
      " 1\n",
      "Total waste of time.\n",
      " 0\n",
      "If this is critically acclaimed and highly rated, how bad must a flick be to get a low rating\n",
      " 0\n",
      "Clearly, Black Panther represents a great step forward on their way to exceptional films and not simply good movies, or movies that meet\n",
      " 0\n",
      "Results from  ../project1/test_sentences.txt  printed to: output.txt\n"
     ]
    }
   ],
   "source": [
    "my_clf_nl.test_file(\"../project1/test_sentences.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
